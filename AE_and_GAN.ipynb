{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generative models.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6my3XG5p9Ed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://www.cs.columbia.edu/CAVE/databases/pubfig/download/lfw_attributes.txt\n",
        "!wget http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz\n",
        "!wget http://vis-www.cs.umass.edu/lfw/lfw.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_paZ0FQoQ5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lfw_dataset import load_lfw_dataset\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "#import download_utils\n",
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhdpT73ysbXX",
        "colab_type": "text"
      },
      "source": [
        "## Utils and parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJwJCa2pt5kl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
        "GAN_CODE_SIZE = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-r6xKNVsfEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.ConvTranspose2d):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "def sample_noise_batch(bsize):\n",
        "    return torch.randn(bsize, GAN_CODE_SIZE).to(DEVICE)\n",
        "\n",
        "def sample_data_batch(bsize, data):\n",
        "    idxs = np.random.choice(np.arange(data.shape[0]), size=bsize)\n",
        "    ind_to_show = np.random.choice(bsize)\n",
        "    tensor_data = torch.Tensor(data[idxs].transpose((0,3,1,2)))\n",
        "    return tensor_data.to(DEVICE)\n",
        "\n",
        "def sample_images(nrow, ncol, images, data, sharp=False):\n",
        "    if np.var(images)!=0:\n",
        "        images = images.clip(np.min(data),np.max(data))\n",
        "    for i in range(nrow*ncol):\n",
        "        plt.subplot(nrow,ncol,i+1)\n",
        "        if sharp:\n",
        "            plt.imshow(images[i].reshape(data.shape[1:]),cmap=\"gray\", interpolation=\"none\")\n",
        "        else:\n",
        "            plt.imshow(images[i].reshape(data.shape[1:]),cmap=\"gray\")\n",
        "    plt.show()\n",
        "\n",
        "def sample_probas(desc_real_prediction, desc_gen_prediction):\n",
        "    plt.title('Generated vs real data')\n",
        "    plt.hist(np.exp(desc_real_prediction)[:,1],\n",
        "             label='D(x)', alpha=0.5,range=[0,1])\n",
        "    plt.hist(np.exp(desc_gen_prediction)[:,1],\n",
        "             label='D(G(z))',alpha=0.5,range=[0,1])\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "def show_results(test_image_tensor, reconstructed_tensor):\n",
        "    image = test_image_tensor.numpy().transpose((1,2,0)) # detach? cpu?\n",
        "    reconstructed = reconstructed_tensor.cpu().detach().numpy().squeeze().transpose((1,2,0))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title(\"Original\")\n",
        "    plt.imshow(np.clip(image + 0.5, 0, 1))\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title(\"Reconstructed\")\n",
        "    plt.imshow(np.clip(reconstructed + 0.5, 0, 1))\n",
        "    plt.show()\n",
        "\n",
        "##### Common convolutional block \n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, inp_depth=32, first=False):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        out_depth = 32 if first else inp_depth*2\n",
        "        self.conv = nn.Conv2d(inp_depth, out_depth, 3, padding=1)\n",
        "        self.max_pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "        self.elu = nn.ELU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.elu(out)\n",
        "        return self.max_pool(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iduth-xmr8rj",
        "colab_type": "text"
      },
      "source": [
        "##Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZuLc_KSsl7r",
        "colab_type": "text"
      },
      "source": [
        "### Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utaWgedzr-2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters:\n",
        "NROF_ITERS = 4\n",
        "\n",
        "class TranspConvBlock(nn.Module):\n",
        "    def __init__(self, inp_depth=32, last=False):\n",
        "        super(TranspConvBlock, self).__init__()\n",
        "        out_depth = 3 if last else inp_depth//2\n",
        "        self.tr_conv = nn.ConvTranspose2d(inp_depth, out_depth, 3, stride=2, padding=1, output_padding=1)\n",
        "        self.f_act = nn.Identity() if last else nn.ELU() # identity ??\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.tr_conv(x)\n",
        "        return self.f_act(out)\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, code_size = 32):\n",
        "        super(Model,self).__init__()\n",
        "        self._init_encoder(code_size)\n",
        "        self._init_decoder(code_size)\n",
        "        self.elu = nn.ELU()\n",
        "\n",
        "        for m in self.modules():\n",
        "            m.apply(init_weights)\n",
        "\n",
        "    def _init_encoder(self, code_size):\n",
        "        in_depths = [32, 64, 128]\n",
        "\n",
        "        self.conv_blocks=[ConvBlock(3, True)]\n",
        "        for depth in in_depths:\n",
        "            self.conv_blocks.append(ConvBlock(depth))\n",
        "        self.conv_blocks = nn.Sequential(*self.conv_blocks)\n",
        "\n",
        "        self.flat = nn.Flatten()\n",
        "        self.fc_enc = nn.Linear(1024, code_size) \n",
        "\n",
        "    def _init_decoder(self, code_size):\n",
        "        in_depths = [256, 128, 64]\n",
        "\n",
        "        self.fc_dec = nn.Linear(code_size, 1024)\n",
        "        self.conv_tr_blocks = []\n",
        "        for depth in in_depths:\n",
        "            self.conv_tr_blocks.append(TranspConvBlock(depth))\n",
        "        self.conv_tr_blocks.append(TranspConvBlock(32, True))\n",
        "        self.conv_tr_blocks = nn.Sequential(*self.conv_tr_blocks)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv_blocks(x)\n",
        "        out = self.flat(out)\n",
        "        out = self.elu(self.fc_enc(out))\n",
        "        out = self.elu(self.fc_dec(out))\n",
        "        out = out.unflatten(1, (('A', 256),('B', 2), ('C',2)))\n",
        "        out = out.rename(None)\n",
        "        out = self.conv_tr_blocks(out)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dea_Fn49tzod",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjFCNuK96QXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data preparing\n",
        "X, attr = load_lfw_dataset(use_raw=True, dimx=32, dimy=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrOKoCrUtyVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg_batch_size = 32\n",
        "cfg_ckpt_path = 'AE/checkpoint'\n",
        "cfg_ckpt_load = False \n",
        "\n",
        "class Train:\n",
        "    def __init__(self, X):\n",
        "        self._prepare_data(X)\n",
        "        self.model = Model()\n",
        "        self.model.to(DEVICE)\n",
        "\n",
        "        self.optim = optim.Adamax(self.model.parameters())\n",
        "        self.crit = nn.MSELoss()\n",
        "        self.nrof_epochs = 25\n",
        "        self.cur_epoch, self.global_step = 0, 0\n",
        "        self.epoch_size = len(self.dataset) // cfg_batch_size +1\n",
        "    \n",
        "    def _prepare_data(self,X):\n",
        "        X = X.astype('float32') / 255.0 - 0.5\n",
        "        X_train, X_test = train_test_split(X, test_size=0.1, random_state=42)\n",
        "\n",
        "        tr_x_tensor = torch.Tensor(X_train.transpose((0,3,1,2)))\n",
        "        tst_x_tensor = torch.Tensor(X_test.transpose((0,3,1,2)))\n",
        "        self.dataset = TensorDataset(tr_x_tensor)\n",
        "        self.tst_dataset = TensorDataset(tst_x_tensor)\n",
        "        self.dataloader = DataLoader(self.dataset, batch_size = cfg_batch_size)\n",
        "        self.tst_dataloader = DataLoader(self.tst_dataset, batch_size = cfg_batch_size)\n",
        "\n",
        "    def save_model(self):\n",
        "        if not os.path.exists(os.path.dirname(cfg_ckpt_path)):\n",
        "            os.makedirs(os.path.dirname(cfg_ckpt_path))\n",
        "        torch.save({'step':self.global_step,\n",
        "                    'model':self.model.state_dict(),\n",
        "                    'opt':self.optim.state_dict()\n",
        "                    },\n",
        "                   cfg_ckpt_path)\n",
        "        print('Model saved')\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            ckpt = torch.load(cfg_ckpt_path)\n",
        "            self.cur_epoch = ckpt['step'] // self.epoch_size\n",
        "            self.global_step = ckpt['step'] + 1\n",
        "            self.model.load_state_dict(ckpt['model'])\n",
        "            self.optim.load_state_dict(ckpt['opt'])\n",
        "            print('Model loaded')\n",
        "        except FileNotFoundError as FNFer:\n",
        "            raise FNFer\n",
        "\n",
        "    def train_epoch(self):\n",
        "        self.model.train()\n",
        "        for batch_idx, batch in enumerate(self.dataloader):\n",
        "            inputs, outputs = batch[0].to(DEVICE), batch[0].to(DEVICE) \n",
        "            self.optim.zero_grad()\n",
        "\n",
        "            reconstruct = self.model(inputs)\n",
        "            loss = self.crit(reconstruct, outputs)\n",
        "            \n",
        "            if batch_idx%100==0:\n",
        "                print('{} step passed'.format(batch_idx))\n",
        "                ind = np.random.choice(len(self.tst_dataset))\n",
        "                tst_image = self.tst_dataset[ind][0]\n",
        "                reconstruct = self.model(tst_image.unsqueeze(0).to(DEVICE))\n",
        "                show_results(tst_image, reconstruct)\n",
        "\n",
        "            loss.backward()\n",
        "            self.optim.step()\n",
        "\n",
        "    def train(self):\n",
        "        if cfg_ckpt_load:\n",
        "            self.load_model()\n",
        "\n",
        "        for epoch in range(self.cur_epoch,self.cur_epoch+self.nrof_epochs):\n",
        "            self.train_epoch()\n",
        "            self.save_model()\n",
        "    \n",
        "    def evaluate(self):\n",
        "        self.load_model()\n",
        "        self.model.eval()\n",
        "        tr_loss, tst_loss, tr_len, tst_len = 0, 0, 0, 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(self.dataloader):\n",
        "            inputs, outputs = batch[0].to(DEVICE), batch[0].to(DEVICE) \n",
        "\n",
        "            reconstruct = self.model(inputs)\n",
        "            tr_loss = self.crit(reconstruct, outputs)\n",
        "            tr_len += 1\n",
        "        \n",
        "        for batch_idx, batch in enumerate(self.tst_dataloader):\n",
        "            inputs, outputs = batch[0].to(DEVICE), batch[0].to(DEVICE) \n",
        "\n",
        "            reconstruct = self.model(inputs)\n",
        "            tst_loss = self.crit(reconstruct, outputs)\n",
        "            tst_len += 1\n",
        "\n",
        "        tr_loss/=tr_len\n",
        "        tst_loss/=tst_len\n",
        "\n",
        "        ind = np.random.choice(len(self.tst_dataset))\n",
        "        tst_image = self.tst_dataset[ind][0]\n",
        "        reconstruct = self.model(tst_image.unsqueeze(0).to(DEVICE))\n",
        "        show_results(tst_image, reconstruct)\n",
        "\n",
        "        print(\"Train loss: {:.6f}\\nTest loss: {:.6f}\".format(tr_loss, tst_loss))\n",
        "\n",
        "\n",
        "Tr_model = Train(X)\n",
        "Tr_model.train()\n",
        "#Tr_model.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5R049mLwbZT",
        "colab_type": "text"
      },
      "source": [
        "## GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmhSXWDExCPg",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXH_DVftxD0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator,self).__init__()\n",
        "        in_depths = [32, 64, 128]\n",
        "        self.conv_blocks = []\n",
        "\n",
        "        self.conv_blocks.append(ConvBlock(3, True))\n",
        "        for depth in in_depths:\n",
        "            self.conv_blocks.append(ConvBlock(depth))\n",
        "        self.conv_blocks = nn.Sequential(*self.conv_blocks)\n",
        "\n",
        "        self.flat = nn.Flatten()\n",
        "        self.fc_1 = nn.Linear(2304, 256) \n",
        "        self.tanh = nn.Tanh()\n",
        "        self.fc_2 = nn.Linear(256, 2) \n",
        "        self.log_sftmx = nn.LogSoftmax()\n",
        "\n",
        "        for m in self.modules():\n",
        "            m.apply(init_weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv_blocks(x)\n",
        "        out = self.flat(out)        \n",
        "        out = self.fc_1(out)\n",
        "        out = self.tanh(out)\n",
        "        out = self.fc_2(out)\n",
        "        return self.log_sftmx(out)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self,code_size = 256):\n",
        "        super(Generator,self).__init__()\n",
        "        self.fc_1 = nn.Linear(code_size, 640)\n",
        "        self.elu = nn.ELU()\n",
        "        self.transp_conv_1 = nn.ConvTranspose2d(10, 64, 5) \n",
        "        self.transp_conv_2 = nn.ConvTranspose2d(64, 64, 5) \n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.transp_conv_3 = nn.ConvTranspose2d(64, 32, 3) \n",
        "        self.transp_conv_4 = nn.ConvTranspose2d(32, 32, 3) \n",
        "        self.transp_conv_5 = nn.ConvTranspose2d(32, 32, 3)\n",
        "        self.conv = nn.Conv2d(32, 3, 3)\n",
        "\n",
        "        for m in self.modules():\n",
        "            m.apply(init_weights)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.elu(self.fc_1(x))\n",
        "        out = out.unflatten(1, (('A', 10),('B', 8), ('C',8)))\n",
        "        out = out.rename(None)\n",
        "        out = self.elu(self.transp_conv_1(out))\n",
        "        out = self.elu(self.transp_conv_2(out))\n",
        "        out = self.upsample(out)\n",
        "        out = self.elu(self.transp_conv_3(out))\n",
        "        out = self.elu(self.transp_conv_4(out))\n",
        "        out = self.elu(self.transp_conv_5(out))\n",
        "        return self.conv(out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTnaMuyIx-tS",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpV77cNo7US6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading data\n",
        "\n",
        "data, attrs = load_lfw_dataset(dimx=36,dimy=36)\n",
        "data = np.float32(data)/255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi52YPrWyAm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg_batch_size = 100\n",
        "cfg_ckpt_path = 'GAN/checkpoint'\n",
        "cfg_ckpt_load = False \n",
        "\n",
        "class Train:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.disc = Discriminator().to(DEVICE)\n",
        "        self.gen = Generator().to(DEVICE)\n",
        "        self.ada_optim = optim.Adamax(self.gen.parameters())\n",
        "        self.sgd_optim = optim.SGD(self.disc.parameters(),lr=1e-3)\n",
        "        self.crit = nn.MSELoss()\n",
        "    \n",
        "    def save_model(self):\n",
        "        if not os.path.exists(os.path.dirname(cfg_ckpt_path)):\n",
        "            os.makedirs(os.path.dirname(cfg_ckpt_path))\n",
        "        torch.save({\n",
        "                    'disc':self.disc.state_dict(),\n",
        "                    'gen':self.gen.state_dict(),\n",
        "                    'ada_opt':self.ada_optim.state_dict(),\n",
        "                    'sgd_opt':self.sgd_optim.state_dict()\n",
        "                    },\n",
        "                   cfg_ckpt_path)\n",
        "        print('model saved')\n",
        "\n",
        "    def load_model(self):\n",
        "        ckpt = torch.load(cfg_ckpt_path)\n",
        "        self.disc.load_state_dict(ckpt['disc'])\n",
        "        self.gen.load_state_dict(ckpt['gen'])\n",
        "        self.ada_optim.load_state_dict(ckpt['ada_opt'])\n",
        "        self.sgd_optim.load_state_dict(ckpt['sgd_opt'])\n",
        "        print('model loaded')\n",
        "\n",
        "    def train_epoch(self):\n",
        "        self.disc.train()\n",
        "        self.gen.eval() \n",
        "\n",
        "        for i in range(5):\n",
        "            self.sgd_optim.zero_grad()\n",
        "            real_data = sample_data_batch(cfg_batch_size, self.data)\n",
        "            noise = sample_noise_batch(cfg_batch_size)\n",
        "\n",
        "            logp_real = self.disc(real_data)\n",
        "            logp_gen = self.disc(self.gen(noise))\n",
        "\n",
        "            d_loss = -torch.mean(logp_real[:,1] + logp_gen[:,0])\n",
        "            last_layer_params = torch.cat([x.view(-1) for x in self.disc.fc_2.parameters()])\n",
        "            d_loss += torch.mean(last_layer_params**2)\n",
        "            \n",
        "            d_loss.backward()\n",
        "            self.sgd_optim.step()\n",
        "        \n",
        "        self.gen.train()\n",
        "        self.disc.eval()\n",
        "        self.ada_optim.zero_grad()\n",
        "\n",
        "        noise = sample_noise_batch(cfg_batch_size)\n",
        "        logp_gen = self.disc(self.gen(noise))\n",
        "\n",
        "        g_loss = -torch.mean(logp_gen[:,1])\n",
        "        g_loss.backward()\n",
        "        self.ada_optim.step()\n",
        "\n",
        "    def train(self):\n",
        "        if cfg_ckpt_load:\n",
        "            self.load_model()\n",
        "        \n",
        "        for epoch in range(50000):\n",
        "            self.train_epoch()\n",
        "            \n",
        "            if epoch %100==0:\n",
        "                self.disc.eval(), self.gen.eval()\n",
        "                print('epoch',epoch)\n",
        "                noise = sample_noise_batch(6)\n",
        "                images = self.gen(noise).cpu().detach().numpy().transpose((0,2,3,1))\n",
        "                sample_images(2,3,images,self.data,True)\n",
        "                \n",
        "                real_data = sample_data_batch(1000, self.data)\n",
        "                noise = sample_noise_batch(1000)\n",
        "                logp_real = self.disc(real_data).cpu().detach().numpy()\n",
        "                logp_gen = self.disc(self.gen(noise)).cpu().detach().numpy()\n",
        "                sample_probas(logp_real, logp_gen)\n",
        "                self.save_model()\n",
        "\n",
        "Tr_model = Train(data)\n",
        "Tr_model.train()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}